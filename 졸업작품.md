
# 정제조 졸업작품 발표자료
---
# 1. 기능
   
- yolo 학습을 이용해 주차 공간, 표지판 객체 검출 (yolo3_tiny, yolo4_tiny 모델 사용)
- 표지판 트레이서 구현
- 표지판에 따른 주차방향 결정
- 라인이 없는 상태에서 주차 하는 코드 구현
- 모터의 속도에 따라 이미지의 원의 좌표를 갱신헤 정적으로 고정되는것 처럼 보이는 코드 구현
- 코너 검출 알고리즘이 주차를 보조하도록 구현


---

# 2. 블록도


![주차 공간 1리얼](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/eb498cdf-6932-445a-ad3b-963c34a6d493)



---

# 3. 구현결과

# 3.1 yolo 표지판 추론 결과

주차공간과 표지판 둘다 yolo3_tiny 모델을 사용했었는데
정지 표지판은 인식이 잘되지만 우측과 좌측 표지판은 멀리서 보면 사람이 봐도 비슷하고 추론결과 정확성이 떨어졌음 
따라서 표지판은 yolo4_tiny 모델을 사용하여 학습시킴 이로 인해 fps는 조금 내려갔더라도 표지판을 보고 제어가 가능하게 되었음

![표지판](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/dc010b4f-058a-44ba-b791-cb0e80b5958c)


# 3.2 yolo 주차 공간 추론 결과


주행하여 주차 공간을 인식하기 위해서는 굴절된 이미지의 학습데이터가 반드시 필요로 했음
로봇의 시야에서 보이는 이미지들을 학습데이터에 추가하자 인식률이 상승했음

![주차 영역](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/dce2e3f0-a89d-409e-bbdf-174e83149449)

# 3.3 코드 실행 결과

코너 검출알고리즘으로 두개의 모서리를 찾고 그 중심점에 점을 찍어 모터를 제어할때마다 좌표를 갱신해서 주차를 보조할때 사용할수 있게 하였음

![보조 ㄱㄱ](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/aa7f1b11-0e10-4bd2-9d47-e2310ba33d4d)

주차장으로 이동해서 코드를 실행 시켰을때 처음 보이는 모습
표지판 검출에 성공하면 중심점을 향해서 주행함.
아무리 fps 를 높이려고 최대전력모드, 학습데이터 사이즈 줄여서 파라미터를 줄여 보아도 여전히
yolo의가중치 파일은 무거웠음. 특히 오른쪽 왼쪽 표지판 학습의 정확도를 높이기 위해 yolo3_tiny가 아닌 yolo4_tiny를 썼기 때문에
표지판에 가까워질때 속도를 줄이고 표지판 앞까지 도달했어도 미세하게 모터를 조종해 표지판이 정중앙에 위치하도록 한후, 정확히 무슨 표지판인지
판단하게 하였음

![추론중에 모터제어](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/8c1f6ad4-b8f6-4217-9753-7a34fbc409f3)


표지판으로 방향을 잡고 그 방향으로 모터를 회전하다가 주차 공간이 발견이 된다면
주차 공간의 왼쪽 공간에 주차공간에 진입할 각도로 점을 찍음
로봇의 카메라는 굴절된 이미지 이기 때문에 주차 공간이 가까울수록 각도를 높여서 원을 그리고
이 원이 중심점에 위치한 순간 로봇을 전진시킴

![일단 마지막](https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/89e55bf3-2b65-4b99-a916-e2304cb059fd)




---

# 4. 영상


영상 링크 https://www.youtube.com/watch?v=HNU0fb4PwUU



https://github.com/rkskwhdgh123/Capstone-Design/assets/103232943/973042b5-e078-42d0-875a-50a62bdb478e






---
